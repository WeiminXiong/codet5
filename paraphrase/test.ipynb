{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "all_tokens = json.load(open(\"all_tokens.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lemminflect\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "sent = \"I love you.\"\n",
    "tokens = word_tokenize(sent)\n",
    "pos = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('you', 'PRP'), ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n"
     ]
    }
   ],
   "source": [
    "print(wnl.lemmatize(\"beginning\",\n",
    "        \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commence', 'start_out', 'get', 'get_down', 'start', 'lead_off', 'set_about', 'Menachem_Begin', 'begin', 'Begin', 'set_out'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "word = \"begin\"\n",
    "for syn in wordnet.synsets(word):\n",
    "    for lm in syn.lemmas():\n",
    "        synonyms.append(lm.name())\n",
    "print (set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Beginning',)\n",
      "('Menachem_begining',)\n",
      "('get_downing',)\n",
      "('beginning',)\n",
      "('getting',)\n",
      "('start_outing',)\n",
      "('starting',)\n",
      "('set_abouting',)\n",
      "('set_outing',)\n",
      "('commencing',)\n",
      "('beginning',)\n",
      "('starting',)\n",
      "('beginning',)\n",
      "('lead_offing',)\n",
      "('starting',)\n",
      "('commencing',)\n",
      "('beginning',)\n",
      "('beginning',)\n",
      "('beginning',)\n",
      "('beginning',)\n",
      "('starting',)\n",
      "('beginning',)\n",
      "('starting',)\n",
      "('beginning',)\n",
      "('beginning',)\n"
     ]
    }
   ],
   "source": [
    "from lemminflect import getInflection\n",
    "\n",
    "new_set = set()\n",
    "\n",
    "for item in synonyms:\n",
    "    print(getInflection(item, tag='VBG'))\n",
    "    new_set.add(getInflection(item, tag='VBG')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_outing', 'set_outing', 'beginning', 'lead_offing', 'set_abouting', 'commencing', 'Menachem_begining', 'get_downing', 'Beginning', 'starting', 'getting'}\n"
     ]
    }
   ],
   "source": [
    "print(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 00:00:25.306119: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from textattack.constraints.semantics import WordEmbeddingDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_distance = WordEmbeddingDistance(min_cos_sim=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'attack_attrs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10824/1632538159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynonyms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_distance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_item\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/code/lib/python3.7/site-packages/textattack/constraints/semantics/word_embedding_distance.py\u001b[0m in \u001b[0;36m_check_constraint\u001b[0;34m(self, transformed_text, reference_text)\u001b[0m\n\u001b[1;32m     61\u001b[0m         closer than ``self.min_cos_sim`` or ``self.max_mse_dist``.\"\"\"\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_attrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"newly_modified_indices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             raise KeyError(\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'attack_attrs'"
     ]
    }
   ],
   "source": [
    "for item, new_item in zip(synonyms, new_set):\n",
    "    print(word_distance._check_constraint(item, new_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"/home/weimin/CodeT5/CodeT5+/paraphrase/tokens_map.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for value in data.values():\n",
    "    total+=len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "647"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Salesforce/codet5p-770m-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " '<pad>',\n",
       " '<mask>',\n",
       " '<extra_id_99>',\n",
       " '<extra_id_98>',\n",
       " '<extra_id_97>',\n",
       " '<extra_id_96>',\n",
       " '<extra_id_95>',\n",
       " '<extra_id_94>',\n",
       " '<extra_id_93>',\n",
       " '<extra_id_92>',\n",
       " '<extra_id_91>',\n",
       " '<extra_id_90>',\n",
       " '<extra_id_89>',\n",
       " '<extra_id_88>',\n",
       " '<extra_id_87>',\n",
       " '<extra_id_86>',\n",
       " '<extra_id_85>',\n",
       " '<extra_id_84>',\n",
       " '<extra_id_83>',\n",
       " '<extra_id_82>',\n",
       " '<extra_id_81>',\n",
       " '<extra_id_80>',\n",
       " '<extra_id_79>',\n",
       " '<extra_id_78>',\n",
       " '<extra_id_77>',\n",
       " '<extra_id_76>',\n",
       " '<extra_id_75>',\n",
       " '<extra_id_74>',\n",
       " '<extra_id_73>',\n",
       " '<extra_id_72>',\n",
       " '<extra_id_71>',\n",
       " '<extra_id_70>',\n",
       " '<extra_id_69>',\n",
       " '<extra_id_68>',\n",
       " '<extra_id_67>',\n",
       " '<extra_id_66>',\n",
       " '<extra_id_65>',\n",
       " '<extra_id_64>',\n",
       " '<extra_id_63>',\n",
       " '<extra_id_62>',\n",
       " '<extra_id_61>',\n",
       " '<extra_id_60>',\n",
       " '<extra_id_59>',\n",
       " '<extra_id_58>',\n",
       " '<extra_id_57>',\n",
       " '<extra_id_56>',\n",
       " '<extra_id_55>',\n",
       " '<extra_id_54>',\n",
       " '<extra_id_53>',\n",
       " '<extra_id_52>',\n",
       " '<extra_id_51>',\n",
       " '<extra_id_50>',\n",
       " '<extra_id_49>',\n",
       " '<extra_id_48>',\n",
       " '<extra_id_47>',\n",
       " '<extra_id_46>',\n",
       " '<extra_id_45>',\n",
       " '<extra_id_44>',\n",
       " '<extra_id_43>',\n",
       " '<extra_id_42>',\n",
       " '<extra_id_41>',\n",
       " '<extra_id_40>',\n",
       " '<extra_id_39>',\n",
       " '<extra_id_38>',\n",
       " '<extra_id_37>',\n",
       " '<extra_id_36>',\n",
       " '<extra_id_35>',\n",
       " '<extra_id_34>',\n",
       " '<extra_id_33>',\n",
       " '<extra_id_32>',\n",
       " '<extra_id_31>',\n",
       " '<extra_id_30>',\n",
       " '<extra_id_29>',\n",
       " '<extra_id_28>',\n",
       " '<extra_id_27>',\n",
       " '<extra_id_26>',\n",
       " '<extra_id_25>',\n",
       " '<extra_id_24>',\n",
       " '<extra_id_23>',\n",
       " '<extra_id_22>',\n",
       " '<extra_id_21>',\n",
       " '<extra_id_20>',\n",
       " '<extra_id_19>',\n",
       " '<extra_id_18>',\n",
       " '<extra_id_17>',\n",
       " '<extra_id_16>',\n",
       " '<extra_id_15>',\n",
       " '<extra_id_14>',\n",
       " '<extra_id_13>',\n",
       " '<extra_id_12>',\n",
       " '<extra_id_11>',\n",
       " '<extra_id_10>',\n",
       " '<extra_id_9>',\n",
       " '<extra_id_8>',\n",
       " '<extra_id_7>',\n",
       " '<extra_id_6>',\n",
       " '<extra_id_5>',\n",
       " '<extra_id_4>',\n",
       " '<extra_id_3>',\n",
       " '<extra_id_2>',\n",
       " '<extra_id_1>',\n",
       " '<extra_id_0>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def send_request(prompt):\n",
    "    dict = {'model':\"gpt-3.5-turbo\",\n",
    "        'messages' : [{'role': 'user', 'content':prompt}],\n",
    "        'top_p' : 0.9,\n",
    "        'max_tokens':3000,\n",
    "        'frequency_penalty':0,\n",
    "        'presence_penalty':0,}\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer sb-ed07016f987c6bb701b74fcf399c56d067b5a5c8bc3ad177',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    data = json.dumps(dict)\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.post('https://api.openai-sb.com/v1/chat/completions', headers=headers, data=data)\n",
    "        except Exception:\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Given the instruction below:\\n\\\n",
    "```{}```\\n\\\n",
    "Please help me generate 20 paraphrases and do not change its original form and keep its function name and parameters and the test case using the format: \\n\\\n",
    "sentence: \\n\\\n",
    "sentence: \\n\\\n",
    "... \\n\\\n",
    "sentence: \\n\\\n",
    "Remember do not change the example case and the function name and keep its original form\"\n",
    "\n",
    "program = \"\"\"For a given list of input numbers, calculate Mean Absolute Deviation\\n    around the mean of this dataset.\\n    Mean Absolute Deviation is the average absolute difference between each\\n    element and a centerpoint (mean in this case):\\n    MAD = average | x - x_mean |\\n\"\"\"\n",
    "\n",
    "prompt_instance = prompt.format(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_request(prompt_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: Compute the Mean Absolute Deviation for a given list of input numbers based on the mean of the dataset.\n",
      "sentence: Determine the Mean Absolute Deviation by calculating the average absolute difference between each element and the mean of the input numbers.\n",
      "sentence: Find the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the input numbers.\n",
      "sentence: Calculate the Mean Absolute Deviation by finding the average of the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Obtain the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Determine the Mean Absolute Deviation as the average absolute difference between each element and the mean of the input numbers.\n",
      "sentence: Compute the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Find the Mean Absolute Deviation by taking the average of the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Calculate the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Obtain the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the input numbers.\n",
      "sentence: Determine the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the input numbers.\n",
      "sentence: Compute the Mean Absolute Deviation for a given list of input numbers by calculating the average absolute difference between each element and the mean of the dataset.\n",
      "sentence: Determine the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.\n",
      "sentence: Find the Mean Absolute Deviation by taking the average of the absolute differences between each element and the mean of the dataset.\n",
      "sentence: Calculate the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the dataset.\n",
      "sentence: Obtain the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.\n",
      "sentence: Determine the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the dataset.\n",
      "sentence: Compute the Mean Absolute Deviation as the average absolute difference between each element and the mean of the dataset.\n",
      "sentence: Find the Mean Absolute Deviation by calculating the average of the absolute differences between each element and the mean of the dataset.\n",
      "sentence: Calculate the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.\n",
      "sentence: Obtain the Mean Absolute Deviation by taking the average absolute difference between each element and the mean of the dataset.\n"
     ]
    }
   ],
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence: Compute the Mean Absolute Deviation for a given list of input numbers based on the mean of the dataset.',\n",
       " 'sentence: Determine the Mean Absolute Deviation by calculating the average absolute difference between each element and the mean of the input numbers.',\n",
       " 'sentence: Find the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the input numbers.',\n",
       " 'sentence: Calculate the Mean Absolute Deviation by finding the average of the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Obtain the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Determine the Mean Absolute Deviation as the average absolute difference between each element and the mean of the input numbers.',\n",
       " 'sentence: Compute the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Find the Mean Absolute Deviation by taking the average of the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Calculate the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Obtain the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the input numbers.',\n",
       " 'sentence: Determine the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the input numbers.',\n",
       " 'sentence: Compute the Mean Absolute Deviation for a given list of input numbers by calculating the average absolute difference between each element and the mean of the dataset.',\n",
       " 'sentence: Determine the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.',\n",
       " 'sentence: Find the Mean Absolute Deviation by taking the average of the absolute differences between each element and the mean of the dataset.',\n",
       " 'sentence: Calculate the Mean Absolute Deviation by averaging the absolute differences between each element and the mean of the dataset.',\n",
       " 'sentence: Obtain the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.',\n",
       " 'sentence: Determine the Mean Absolute Deviation as the average of the absolute differences between each element and the mean of the dataset.',\n",
       " 'sentence: Compute the Mean Absolute Deviation as the average absolute difference between each element and the mean of the dataset.',\n",
       " 'sentence: Find the Mean Absolute Deviation by calculating the average of the absolute differences between each element and the mean of the dataset.',\n",
       " 'sentence: Calculate the Mean Absolute Deviation by finding the average absolute difference between each element and the mean of the dataset.',\n",
       " 'sentence: Obtain the Mean Absolute Deviation by taking the average absolute difference between each element and the mean of the dataset.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['choices'][0]['message']['content'].split('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humaneval/30\n",
    "original:\"\\n\\ndef get_positive(l: list):\\n    \\\"\\\"\\\"Return only positive numbers in the list.\\n    >>> get_positive([-1, 2, -4, 5, 6])\\n    [2, 5, 6]\\n    >>> get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\\n    [5, 3, 2, 3, 9, 123, 1]\\n    \\\"\\\"\\\"\\n\"\n",
    "\n",
    "top:\"\\n\\ndef get_positive(l: list):\\n    \\\"\\\"\\\"Remove any negative numbers from the list.\\n    >>> get_positive([-1, 2, -4, 5, 6])\\n    [2, 5, 6]\\n    >>> get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\\n    [5, 3, 2, 3, 9, 123, 1]\\n    \\\"\\\"\\\"\\n\"\n",
    "\n",
    "bottom:\"\\n\\ndef get_positive(l: list):\\n    \\\"\\\"\\\"Retain only the numbers that are strictly greater than zero in the list.\\n    >>> get_positive([-1, 2, -4, 5, 6])\\n    [2, 5, 6]\\n    >>> get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\\n    [5, 3, 2, 3, 9, 123, 1]\\n    \\\"\\\"\\\"\\n\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humaneval/27\n",
    "\n",
    "original:\"\\n\\ndef flip_case(string: str) -> str:\\n    \\\"\\\"\\\" For a given string, flip lowercase characters to uppercase and uppercase to lowercase.\\n    >>> flip_case('Hello')\\n    'hELLO'\\n    \\\"\\\"\\\"\\n\"\n",
    "\n",
    "top:\"\\n\\ndef flip_case(string: str) -> str:\\n    \\\"\\\"\\\"\\\"Swap the case of characters in the given string, converting lowercase to uppercase and uppercase to lowercase.\\\"\\n    >>> flip_case('Hello')\\n    'hELLO'\\n    \\\"\\\"\\\"\\n\"\n",
    "\n",
    "bottom:\"\\n\\ndef flip_case(string: str) -> str:\\n    \\\"\\\"\\\"\\\"Reverse the case of letters in the given string, making lowercase uppercase and uppercase lowercase.\\\"\\n    >>> flip_case('Hello')\\n    'hELLO'\\n    \\\"\\\"\\\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.data import stream_jsonl, write_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = stream_jsonl(\"/home/weimin/CodeT5/CodeT5+/paraphrase/human-eval-v2-20210705.jsonl\")\n",
    "problems = list(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_id': 'HumanEval/0', 'prompt': 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n', 'entry_point': 'has_close_elements', 'canonical_solution': '    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n', 'test': \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "for item in problem:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier = \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n\"\n",
    "problem = problems[0]\n",
    "entry_point = problem['entry_point']\n",
    "prompt = problem['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_case(prompt, entry_point):\n",
    "    index = prompt.find(entry_point)\n",
    "    index = prompt.find(entry_point, index+1)\n",
    "    cur_test = frontier\n",
    "    while index !=-1:\n",
    "        s_index = prompt.find('\\n', index)\n",
    "        e_index = prompt.find('\\n', s_index+1)\n",
    "        ass = f\"    assert {prompt[index: s_index].strip()} == {prompt[s_index:e_index].strip()}\\n\"\n",
    "        cur_test += ass.replace(entry_point, \"candidate\")\n",
    "        index = prompt.find(entry_point, index+1)\n",
    "    return cur_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_problems=  []\n",
    "from copy import deepcopy\n",
    "for item in problems:\n",
    "    new_item = deepcopy(item)\n",
    "    prompt = item['prompt']\n",
    "    entry_point = item['entry_point']\n",
    "    cur_test = get_test_case(prompt, entry_point)\n",
    "    new_item['public_test'] = cur_test\n",
    "    new_problems.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl( \"human-eval.jsonl\", new_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"/home/weimin/CodeT5/CodeT5+/paraphrase/augmented_prompt.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "for item in data:\n",
    "    li.append((item['task_id'], len(item['augmented_prompt'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from human_eval.data import stream_jsonl, write_jsonl\n",
    "\n",
    "data = list(stream_jsonl(\"/home/weimin/CodeT5/CodeT5+/humaneval/human-eval.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pprint\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from human_eval.data import write_jsonl, read_problems, stream_jsonl\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "class A:\n",
    "    model = 'Salesforce/codet5p-770m-py'\n",
    "    start_index = 0\n",
    "    end_index = 164\n",
    "    temperature = 0.8\n",
    "    N = 20\n",
    "    max_len = 800\n",
    "    decoding_style = 'sampling'\n",
    "    num_seqs_per_iter = 20\n",
    "    top_p = 0.95\n",
    "    \n",
    "\n",
    "\n",
    "args = A()\n",
    "STOP_SEQS = ['\\nclass', '\\ndef', '\\n#', '\\nif', '\\nprint']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(args.model,\n",
    "                                                trust_remote_code=True,  # False for 220m and 770m models\n",
    "                                                torch_dtype=torch.float16,\n",
    "                                                low_cpu_mem_usage=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "def write_code(augmented_prompt, task_ids=0, model=model, tokenizer=tokenizer, device=device, args=args):\n",
    "    augmented_prompt = augmented_prompt.replace('    ', '\\t')\n",
    "    prompt_batch = [augmented_prompt]\n",
    "    prompt_batch_decoder = [augmented_prompt]\n",
    "\n",
    "    ids_batch = [task_ids]\n",
    "\n",
    "    encoding = tokenizer(prompt_batch, return_tensors=\"pt\", truncation=True, max_length=args.max_len).to(device)\n",
    "    encoding_decoder = tokenizer(prompt_batch_decoder, return_tensors=\"pt\", truncation=True,\n",
    "                                max_length=args.max_len).to(device)\n",
    "    \n",
    "    if args.decoding_style == 'sampling':\n",
    "        loops = int(args.N / args.num_seqs_per_iter)\n",
    "    else:\n",
    "        loops = 1\n",
    "        \n",
    "    completion_seqs = []\n",
    "\n",
    "    for _ in tqdm(range(loops), total=loops, ncols=0):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if args.decoding_style == 'sampling':\n",
    "                gen_tokens = model.generate(**encoding,\n",
    "                                            do_sample=True,\n",
    "                                            temperature=args.temperature,\n",
    "                                            max_length=args.max_len,\n",
    "                                            num_return_sequences=args.num_seqs_per_iter,\n",
    "                                            eos_token_id=tokenizer.eos_token_id,\n",
    "                                            top_p=args.top_p)\n",
    "                # gen_tokens = model.generate(**encoding,\n",
    "                #                             do_sample=False,\n",
    "                #                             temperature = args.temperature,\n",
    "                #                             num_beams=30,\n",
    "                #                             num_return_sequences=args.num_seqs_per_iter)\n",
    "\n",
    "        if gen_tokens is not None:\n",
    "            gen_seqs = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "        else:\n",
    "            gen_seqs = None\n",
    "\n",
    "        if gen_seqs is not None:\n",
    "            assert len(ids_batch) == 1\n",
    "            task_id = ids_batch[0]\n",
    "\n",
    "            for seq_idx, gen_seq in enumerate(gen_seqs):\n",
    "                completion_seq = gen_seq\n",
    "                for stop_seq in STOP_SEQS:\n",
    "                    index = completion_seq.find(stop_seq)\n",
    "                    if index != -1:\n",
    "                        completion_seq = completion_seq[:index]\n",
    "                completion_seq = completion_seq.replace('\\t', '    ')\n",
    "                all_code = augmented_prompt.replace('\\t', '    ') + completion_seq\n",
    "\n",
    "                completion_seqs.append(\n",
    "                    {'task_id': task_id,\n",
    "                    'completion': completion_seq,\n",
    "                    'all_code': all_code,  # final code for evaluation with unit tests,\n",
    "                    'prompt_id': 1\n",
    "                    }\n",
    "                )\n",
    "    return completion_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_probability(prompt, completions):\n",
    "        batch_size = len(completions)\n",
    "        start_tokens = [prompt]*batch_size\n",
    "        encodings = tokenizer(start_tokens, return_tensors='pt')\n",
    "        encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "        labels = tokenizer(completions, truncation=True, max_length=512, padding='max_length', return_tensors='pt')['input_ids'].to(device)\n",
    "        outputs = model(**encodings, labels=labels)\n",
    "        logits = outputs['logits'].detach()\n",
    "        logits_softmax = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        labels_token_prob_list = [logits_softmax[i, range(labels.shape[-1]), labels[i, :]] for i in range(batch_size)]\n",
    "        labels_token_prob_list = torch.stack(labels_token_prob_list)\n",
    "        labels_token_prob_list[labels==0]=1\n",
    "        labels_token_prob_list = torch.log(labels_token_prob_list)\n",
    "        labels_token_prob_list = torch.sum(labels_token_prob_list, dim=-1)/torch.sum(labels!=0, dim=-1)\n",
    "        \n",
    "        return labels_token_prob_list.tolist()\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_prompt_probability(prompt):\n",
    "        batch_size = len(prompt)\n",
    "        start_tokens = ['<s>']*batch_size\n",
    "        encodings = tokenizer(start_tokens, return_tensors='pt')\n",
    "        encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "        labels = tokenizer(prompt, truncation=True, max_length=512, padding='max_length', return_tensors='pt')['input_ids'].to(device)\n",
    "        outputs = model(**encodings, labels=labels)\n",
    "        logits = outputs['logits'].detach()\n",
    "        logits_softmax = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        labels_token_prob_list = [logits_softmax[i, range(labels.shape[-1]), labels[i, :]] for i in range(batch_size)]\n",
    "        labels_token_prob_list = torch.stack(labels_token_prob_list)\n",
    "        labels_token_prob_list[labels==0]=1\n",
    "        labels_token_prob_list = torch.log(labels_token_prob_list)\n",
    "        labels_token_prob_list = torch.sum(labels_token_prob_list, dim=-1)/torch.sum(labels!=0, dim=-1)\n",
    "        \n",
    "        return labels_token_prob_list.tolist()\n",
    "\n",
    "@torch.no_grad()\n",
    "def calculate_reverse_probability(prompt, completions):\n",
    "        batch_size = len(completions)\n",
    "        start_tokens = [prompt]*batch_size\n",
    "        encodings = tokenizer(completions, truncation=True, max_length=512, padding='max_length', return_tensors='pt')\n",
    "        encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "        labels = tokenizer(start_tokens, truncation=True, max_length=512, padding='max_length', return_tensors='pt')['input_ids'].to(device)\n",
    "        outputs = model(**encodings, labels=labels)\n",
    "        logits = outputs['logits'].detach()\n",
    "        logits_softmax = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        labels_token_prob_list = [logits_softmax[i, range(labels.shape[-1]), labels[i, :]] for i in range(batch_size)]\n",
    "        labels_token_prob_list = torch.stack(labels_token_prob_list)\n",
    "        labels_token_prob_list[labels==0]=1\n",
    "        labels_token_prob_list = torch.log(labels_token_prob_list)\n",
    "        labels_token_prob_list = torch.sum(labels_token_prob_list, dim=-1)/torch.sum(labels!=0, dim=-1)\n",
    "        \n",
    "        return labels_token_prob_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:16<00:00, 16.95s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n\\\"\\\"\\\"\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\n# check the correctness of has_close_elements\\nassert \"\n",
    "gen_test_1 = write_code(sentence1)\n",
    "completion_1 = [item['completion'] for item in gen_test_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(has_close_elements([1, 2, 3], 1.5) == True)\\nassert (has_close_elements([1, 2, 3], 0.5) == False)\\nassert (has_close_elements([1, 2, 3], -0.5) == False)\\nassert (has_close_elements([1, 2, 3], 1.5) == False)\\nassert (has_close_elements([1, 2, 3], 1) == False)\\nassert (has_close_elements([1, 2, 3], -1) == False)\\nassert (has_close_elements([1, 2, 3], 2) == True)\\nassert (has_close_elements([1, 2, 3], 2.5) == True)\\nassert (has_close_elements([1, 2, 3], -2.5) == True)\\nassert (has_close_elements([1, 2, 3], 3) == True)\\nassert (has_close_elements([1, 2, 3], 3.5) == True)\\nassert (has_close_elements([1, 2, 3], 3.5) == True)\\nassert (has_close_elements([1, 2, 3], 3.5) == True)\\nassert (has_close_elements([1, 2, 3], 3.5) == True)\\nassert (has_close_elements([1, 2, 3], 3.5) == True)\\nassert (has_close_elements([1, 2, 3], -3.5) == False)\\nassert (has_close_elements([1, 2, 3], 0.5) == False)\\n',\n",
       " '(has_close_elements([1.0, 2.0, 3.0], 0.001) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0], 0.001) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0], 0.0001) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0], 0.00001) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0], 0.0001) == False)\\n',\n",
       " '(has_close_elements([1, 2, 3, 4, 5, 6], 0.1) == False)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6], 0.1) == True)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6], 0.5) == False)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6], 0.5) == True)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6], 1) == True)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6], 1) == False)\\n',\n",
       " '(has_close_elements([1, 1, 2, 2], 2) == True)\\nassert (has_close_elements([1, 1, 2, 2], 2.1) == False)\\n',\n",
       " '(has_close_elements([1, 2, 3, 4], 1.0) == True)\\nassert (has_close_elements([1, 2, 3, 4], 0.0) == False)\\nassert (has_close_elements([1, 2, 3, 4], 1.1) == True)\\nassert (has_close_elements([1, 2, 3, 4], 1.2) == True)\\nassert (has_close_elements([1, 2, 3, 4], 0.2) == True)\\nassert (has_close_elements([1, 2, 3, 4], 1.3) == False)\\nassert (has_close_elements([1, 2, 3, 4], 0.3) == False)\\nassert (has_close_elements([1, 2, 3, 4], 0.4) == False)\\n',\n",
       " '(has_close_elements([5, 7, 9], 4) == True)\\nassert (has_close_elements([5, 9, 7], 4) == False)\\nassert (has_close_elements([5, 9, 10], 4) == False)\\nassert (has_close_elements([5, 9, 10], 5) == True)\\n',\n",
       " '(has_close_elements([1, 1.1, 1, 3, 6.4, 5.5], 0.5) == True)\\nassert (has_close_elements([1, 1.1, 1, 3, 6.4, 5.5], 0.1) == False)\\n',\n",
       " '(has_close_elements([2.4, 2.5, 2.6], 2.3) is False)\\nassert (has_close_elements([2.4, 2.5, 2.6], 1.5) is True)\\n',\n",
       " 'has_close_elements([1.0, 3.0, 4.0], 0.00001) == True\\nassert has_close_elements([1.0, 3.0, 4.0], -0.00001) == False\\nassert has_close_elements([1.0, 3.0, 4.0], 0.0001) == True\\nassert has_close_elements([1.0, 3.0, 4.0], 0.001) == False\\n',\n",
       " 'has_close_elements([1.5, 3.1, 4.7, 7.5], 0.0)',\n",
       " '(has_close_elements([1, 2, 3, 4], 3) == True)\\nassert (has_close_elements([3, 2, 4, 1], 3) == False)\\nassert (has_close_elements([1, 2, 3, 4, 5], 3) == True)\\nassert (has_close_elements([1, 2, 3, 4, 5, 6, 7], 3) == False)\\n',\n",
       " '(has_close_elements([1, 2, 3, 4], 1) is False)\\nassert (has_close_elements([1, 2, 3, 4], 2) is True)\\nassert (has_close_elements([1, 2, 3, 4], 1.5) is False)\\nassert (has_close_elements([1, 2, 3, 4], 3.5) is True)\\nassert (has_close_elements([1, 2, 3, 4], 2.5) is False)\\nassert (has_close_elements([1, 2, 3, 4], 3.5) is False)\\nassert (has_close_elements([1, 2, 3, 4], -4.5) is False)\\nassert (has_close_elements([1, 2, 3, 4], 0.5) is True)\\nassert (has_close_elements([1, 2, 3, 4], -0.5) is True)\\n',\n",
       " '(has_close_elements([1.0, 2.0], 0.01) == True)\\nassert (has_close_elements([1.0, 1.0], 0.01) == False)\\nassert (has_close_elements([1.0, 2.0], 0.001) == True)\\nassert (has_close_elements([1.0, 1.0], 0.001) == False)\\nassert (has_close_elements([2.0, 1.0], 0.001) == True)\\n',\n",
       " 'has_close_elements([1, 2, 4, 5], 0.5) == True\\nassert has_close_elements([1, 2, 4, 5], 1.0) == False\\nassert has_close_elements([1, 2, 4, 5], 2.0) == True\\nassert has_close_elements([1, 2, 4, 5], 3.0) == False\\n',\n",
       " '(has_close_elements([1, 2, 3, 4], 1) == True)\\nassert (has_close_elements([1, 2, 3, 4], 2) == False)\\nassert (has_close_elements([1, 2, 3, 4], -1) == False)\\nassert (has_close_elements([1, 2, 3, 4], 0) == False)\\n',\n",
       " '(has_close_elements([1, 5, 10, 100], 5) is True)\\nassert (has_close_elements([1, 5, 10, 100], 1) is False)\\nassert (has_close_elements([1, 5, 10, 100], 0) is True)\\nassert (has_close_elements([1, 5, 10, 100], -1) is False)\\n\\n',\n",
       " '(has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.01) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], -0.01) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.0) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.1) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.2) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.3) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.4) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.5) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.6) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.7) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.8) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.9) == True)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 0.999) == False)\\nassert (has_close_elements([1.0, 2.0, 3.0, 4.0, 5.0], 1.0) == True)\\n',\n",
       " '(has_close_elements([1, 2, 3, 4, 5], 2))\\nassert (has_close_elements([2, 2, 2, 2, 2, 2], 2))\\nassert (not has_close_elements([1, 2, 3, 4, 5], 0))\\n',\n",
       " '(has_close_elements([1, 2, 4, 5], 2.5) == True)\\nassert (has_close_elements([2, 3, 4, 5], 2.0) == True)\\nassert (has_close_elements([2, 3, 4, 5], 1.0) == False)\\nassert (has_close_elements([2, 3, 4, 5], 0.0) == False)\\nassert (has_close_elements([2, 3, 4, 5], 1.1) == False)\\nassert (has_close_elements([2, 3, 4, 5], -0.5) == False)\\n',\n",
       " '(has_close_elements([0, 2, 3, 4, 5], 3.0)) == True\\nassert (has_close_elements([0, 2, 3, 4, 5], 0.0)) == False\\nassert (has_close_elements([0, 2, 3, 4, 5], 4.0)) == False\\nassert (has_close_elements([0, 2, 3, 4, 5], -4.0)) == False']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:03<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_1 = write_code(sentence1)\n",
    "completion_1 = [item['completion'] for item in gen_code_1]\n",
    "probility_1 = calculate_probability(sentence1, completion_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:02<00:00,  2.81s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_2 = write_code(sentence2)\n",
    "completion_2 = [item['completion'] for item in gen_code_2]\n",
    "probility_2 = calculate_probability(sentence2, completion_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(n1 - n2) < threshold for n1, n2 in zip(numbers[:-1], numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if numbers[i] > numbers[i + 1]:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(number - other) <= threshold for number, other in zip(numbers, numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if numbers[i] > numbers[i + 1]:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(number1 - number2) <= threshold for number1, number2 in zip(numbers[:-1], numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(n1 - n2) <= threshold for n1, n2 in zip(numbers, numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(n1 - n2) <= threshold for n1, n2 in zip(numbers[:-1], numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if numbers[i] > numbers[i + 1]:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if abs(numbers[i] - numbers[i + 1]) > threshold:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if abs(numbers[i] - numbers[i + 1]) > threshold:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(number - other) <= threshold for number, other in zip(numbers, numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if numbers[i] > numbers[i + 1] and abs(numbers[i] - numbers[i + 1]) < threshold:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(n1 - n2) < threshold for n1, n2 in zip(numbers, numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(number - other) <= threshold for number, other in zip(numbers, numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if abs(numbers[i] - numbers[i + 1]) > threshold:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if abs(numbers[i] - numbers[i + 1]) > threshold:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(number1 - number2) <= threshold for number1, number2 in zip(numbers[:-1], numbers[1:]))\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    for i in range(len(numbers) - 1):\\n        if numbers[i] < numbers[i + 1]:\\n            return True\\n    return False\\n\\n',\n",
       " 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n    return any(abs(num1 - num2) <= threshold for num1, num2 in zip(numbers, numbers[1:]))\\n\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_code2 = [sentence2+item for item in completion_2]\n",
    "all_code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:02<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence3 = \"from typing import List\\n\\n\\ndef all_prefixes(string: str) -> List[str]:\\n    \\\"\\\"\\\" Return list of all prefixes from shortest to longest of the input string\\n    >>> all_prefixes('abc')\\n    ['a', 'ab', 'abc']\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_3 = write_code(sentence3)\n",
    "completion_3 = [item['completion'] for item in gen_code_3]\n",
    "probility_3 = calculate_probability(sentence3, completion_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + str(i) for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + prefix for prefix in all_prefixes(string[1:])]\\n\\n',\n",
       " '    if len(string) == 0:\\n        return []\\n    return [string[0]] + all_prefixes(string[1:])\\n\\n',\n",
       " '    if len(string) == 0:\\n        return []\\n    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + str(i) for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[0]] + [string[i:j] for i in range(1, len(string)) for j in range(i + 1)]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + x for x in range(1, len(string))]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[0]] + [string[i:j] for i in range(1, len(string)) for j in range(i + 1)]\\n\\n',\n",
       " '    return [string[0]] + [string[i] for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[:i] for i in range(1, len(string))]\\n\\n',\n",
       " '    if len(string) == 0:\\n        return []\\n    return [string[:i] for i in range(1, len(string) + 1)]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + x for x in range(1, len(string))]\\n\\n',\n",
       " '    return [string[0]] + [string[0] + str(i) for i in range(1, len(string))]\\n\\n',\n",
       " '    return [string[0]] + [string[i] for i in range(1, len(string))]\\n\\n']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.419189453125,\n",
       " -0.419189453125,\n",
       " -0.286376953125,\n",
       " -0.419189453125,\n",
       " -0.434326171875,\n",
       " -0.2471923828125,\n",
       " -0.434326171875,\n",
       " -0.434326171875,\n",
       " -0.434326171875,\n",
       " -0.434326171875,\n",
       " -0.263916015625,\n",
       " -0.434326171875,\n",
       " -0.228515625,\n",
       " -0.419189453125,\n",
       " -0.2471923828125,\n",
       " -0.434326171875,\n",
       " -0.419189453125,\n",
       " -0.419189453125,\n",
       " -0.419189453125,\n",
       " -0.434326171875]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probility_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:03<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence4 = \"\\n\\ndef pairs_sum_to_zero(l):\\n    \\\"\\\"\\\"\\n    >>> pairs_sum_to_zero([1, 3, 5, 0])\\n    False\\n    >>> pairs_sum_to_zero([1, 3, -2, 1])\\n    False\\n    >>> pairs_sum_to_zero([1, 2, 3, 7])\\n    False\\n    >>> pairs_sum_to_zero([2, 4, -5, 3, 5, 7])\\n    True\\n    >>> pairs_sum_to_zero([1])\\n    False\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_4 = write_code(sentence4)\n",
    "completion_4 = [item['completion'] for item in gen_code_4]\n",
    "probility_4 = calculate_probability(sentence4, completion_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:14<00:00, 14.14s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence5 = \"from typing import List\\n\\n\\ndef string_xor(a: str, b: str) -> str:\\n    \\\"\\\"\\\" Input are two strings a and b consisting only of 1s and 0s.\\n    Perform binary XOR on these inputs and return result also as a string.\\n    >>> string_xor('010', '110')\\n    '100'\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_5 = write_code(sentence5)\n",
    "completion_5 = [item['completion'] for item in gen_code_5]\n",
    "probility_5 = calculate_probability(sentence5, completion_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:02<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence6 = \"\\n\\ndef common(l1: list, l2: list):\\n    \\\"\\\"\\\"Formulate a function named \\\"common_elements\\\" that accepts two lists and returns a sorted list of unique common elements.\\n    >>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\\n    [1, 5, 653]\\n    >>> common([5, 3, 2, 8], [3, 2])\\n    [2, 3]\\n\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_6 = write_code(sentence6)\n",
    "completion_6 = [item['completion'] for item in gen_code_6]\n",
    "all_code_6 = [sentence6+item for item in completion_6]\n",
    "probility_6 = calculate_probability(sentence6, completion_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:13<00:00, 13.94s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence7 = \"\\n\\ndef triangle_area(a, h):\\n    \\\"\\\"\\\"Given length of a side and high return area for a triangle.\\n    >>> triangle_area(5, 3)\\n    7.5\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_7 = write_code(sentence7)\n",
    "completion_7 = [item['completion'] for item in gen_code_7]\n",
    "all_code_7 = [sentence7+item for item in completion_7]\n",
    "probility_7 = calculate_probability(sentence7, completion_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 1/1 [00:13<00:00, 13.76s/it]\n"
     ]
    }
   ],
   "source": [
    "sentence8 = \"\\n\\ndef triangle_area(a, h):\\n    \\\"\\\"\\\"Use the given side length and height as parameters to calculate the area of a triangle.\\n    >>> triangle_area(5, 3)\\n    7.5\\n    \\\"\\\"\\\"\\n\"\n",
    "gen_code_8 = write_code(sentence8)\n",
    "completion_8 = [item['completion'] for item in gen_code_8]\n",
    "all_code_8 = [sentence8+item for item in completion_8]\n",
    "probility_8 = calculate_probability(sentence8, completion_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8455078125 -1.560546875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(calculate_prompt_probability(all_code_7)), np.mean(calculate_prompt_probability(all_code_8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.61923828125 -0.5615234375\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(probility_7), np.mean(probility_8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.8525390625,\n",
       " -1.8349609375,\n",
       " -1.8349609375,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8349609375,\n",
       " -1.8349609375,\n",
       " -1.8525390625,\n",
       " -1.8349609375,\n",
       " -1.8349609375,\n",
       " -1.8349609375,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8349609375,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8525390625,\n",
       " -1.8525390625]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prompt_probability(all_code_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n',\n",
       " '    return a * h\\n\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.99609375 -1.6796875\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(calculate_reverse_probability(sentence7, completion_7)), np.mean(calculate_reverse_probability(sentence8, completion_8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 653]\n"
     ]
    }
   ],
   "source": [
    "def common(l1: list, l2: list):\n",
    "    \"\"\"Create a function that returns a sorted list of unique elements that are common to both input lists.\n",
    "    >>> common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n",
    "    [1, 5, 653]\n",
    "    >>> common([5, 3, 2, 8], [3, 2])\n",
    "    [2, 3]\n",
    "\n",
    "    \"\"\"\n",
    "    common_elements = []\n",
    "    for i in l1:\n",
    "        if i in l2:\n",
    "            common_elements.append(i)\n",
    "    return sorted(set(common_elements))\n",
    "print(common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = sentence5\n",
    "completions = [completion_5[5]]\n",
    "batch_size = len(completions)\n",
    "start_tokens = [prompt]*batch_size\n",
    "encodings = tokenizer(start_tokens, return_tensors='pt')\n",
    "encodings = {k: v.to(device) for k, v in encodings.items()}\n",
    "labels = tokenizer(completions, truncation=True, max_length=512, padding='max_length', return_tensors='pt')['input_ids'].to(device)\n",
    "# labels[labels==0]=-100\n",
    "outputs = model(**encodings, labels=labels)\n",
    "logits = outputs['logits'].detach()\n",
    "logits_softmax = torch.softmax(logits, dim=-1)\n",
    "\n",
    "labels_token_prob_list = [logits_softmax[i, range(labels.shape[-1]), labels[i, :]] for i in range(batch_size)]\n",
    "labels_token_prob_list = torch.stack(labels_token_prob_list)\n",
    "# labels_token_prob_list[labels==0]=1\n",
    "# labels_token_prob_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 8.9258e-01, 5.0781e-01, 2.8198e-02, 8.5059e-01, 9.6289e-01,\n",
       "         7.6074e-01, 9.8779e-01, 9.9951e-01, 9.9951e-01, 9.8535e-01, 8.9453e-01,\n",
       "         9.4336e-01, 9.8193e-01, 9.7266e-01, 9.2822e-01, 9.8242e-01, 9.8145e-01,\n",
       "         9.9902e-01, 0.0000e+00, 1.3709e-06, 1.4365e-05, 4.3511e-06, 3.6240e-05,\n",
       "         3.0696e-05, 3.4630e-05, 2.4974e-05, 6.9141e-06, 9.9540e-06, 1.5140e-05,\n",
       "         1.1504e-05, 2.6762e-05, 2.9266e-05, 2.7895e-05, 1.7881e-07, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08, 5.9605e-08,\n",
       "         5.9605e-08, 5.9605e-08]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_token_prob_list\n",
    "# outputs['loss']\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.344970703125,\n",
       " -0.9462890625,\n",
       " -0.89208984375,\n",
       " -0.92431640625,\n",
       " -0.5634765625,\n",
       " -inf,\n",
       " -0.49951171875,\n",
       " -0.9384765625,\n",
       " -1.2158203125,\n",
       " -0.677734375,\n",
       " -inf,\n",
       " -1.318359375,\n",
       " -1.23046875,\n",
       " -1.25,\n",
       " -1.0869140625,\n",
       " -1.248046875,\n",
       " -1.1640625,\n",
       " -1.033203125,\n",
       " -1.3203125,\n",
       " -1.380859375]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probility_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"    return ''.join([str(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a))])\\n\\n\",\n",
       " \"    return ''.join([str(int(a[i]) ^ int(b[i])) for i in range(len(a))])\\n\\n\",\n",
       " \"    return ''.join(str(int(a[i]) ^ int(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(chr(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(str(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(str(int(x) ^ int(y)) for x, y in zip(a, b))\\n\\n\",\n",
       " '    return str(int(a, 2) ^ int(b, 2))\\n\\n',\n",
       " '    return str(int(a, 2) ^ int(b, 2))\\n\\n',\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(chr(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(str(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join([str(int(a[i]) ^ int(b[i])) for i in range(len(a))])\\n\\n\",\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " '    return str(int(a, 2) ^ int(b, 2))\\n\\n',\n",
       " \"    return ''.join([str(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a))])\\n\\n\",\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(str(int(a[i], 2) ^ int(b[i], 2)) for i in range(len(a)))\\n\\n\",\n",
       " \"    return ''.join(chr(ord(a[i]) ^ ord(b[i])) for i in range(len(a)))\\n\\n\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    return str(int(a, 2) ^ int(b, 2))\\n',\n",
       " '    return bin(int(a, 2) ^ int(b, 2))[',\n",
       " '    return bin(int(a, 2) ^ int(b, 2)).',\n",
       " '    return str(bin(int(a, 2) ^ int(b, 2',\n",
       " '\\n    return str(int(a, 2) ^ int(b, 2))',\n",
       " \"    return '{0:b}'.format(int(a, 2) ^ int\",\n",
       " '    return bin(int(a, 2) ^ int(b, 2))\\n',\n",
       " \"    return format(int(a, 2) ^ int(b, 2), '\",\n",
       " \"    result = ''\\n    for i in range(len(a)):\\n    \",\n",
       " '\\n    return bin(int(a, 2) ^ int(b, 2))',\n",
       " '    return \"{0:b}\".format(int(a, 2) ^ int',\n",
       " '    if len(a)!= len(b):\\n        raise ValueError(f',\n",
       " '    result = \"\"\\n    for i in range(len(a)):\\n    ',\n",
       " '    if len(a)!= len(b):\\n        raise ValueError\\n    ',\n",
       " \"    return ''.join([str(int(x) ^ int(y)) for\",\n",
       " '    result = []\\n    for i in range(len(a)):\\n    ',\n",
       " \"    return ''.join([str(int(a[i]) ^ int(b\",\n",
       " '\\n    return bin(int(a, 2) ^ int(b, 2)',\n",
       " \"    if len(a)!= len(b):\\n        raise ValueError('Strings\",\n",
       " \"    if len(a)!= len(b):\\n        raise ValueError('The\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.19873046875,\n",
       " -0.347412109375,\n",
       " -0.1904296875,\n",
       " -0.260009765625,\n",
       " -0.359375,\n",
       " -0.306640625,\n",
       " -0.359375,\n",
       " -0.260009765625,\n",
       " -0.306640625,\n",
       " -0.366455078125,\n",
       " -0.275634765625,\n",
       " -0.306640625,\n",
       " -0.306640625,\n",
       " -0.306640625,\n",
       " -0.387939453125,\n",
       " -0.3740234375,\n",
       " -0.2069091796875,\n",
       " -0.381591796875,\n",
       " -0.260009765625,\n",
       " -0.306640625]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probility_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    l.sort()\\n    for i in range(len(l) - 1):\\n        if l[i] + l[i + 1] == 0:\\n            return True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    l.sort()\\n    for i in range(len(l)-1):\\n        if l[i] == l[i+1]:\\n            return True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = 1\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n',\n",
       " '    d = {}\\n    for i in l:\\n        if i in d:\\n            return True\\n        else:\\n            d[i] = True\\n    return False\\n\\n']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.276611328125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.32666015625,\n",
       " -0.25048828125,\n",
       " -0.2607421875,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125,\n",
       " -0.25048828125]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probility_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
